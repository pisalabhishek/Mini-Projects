{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3dc98e-cf42-4d69-a0e9-243b5f70350a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.18.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import torch\n",
    "from pdfminer.high_level import extract_text\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import gradio\n",
    "print(gradio.__version__)  # Check version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27914c9-487b-45e6-99d8-083dc1efdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NLP models\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9c7043-2ec9-45ef-941f-4a4f4125e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        text = extract_text(pdf_path)\n",
    "        if not text.strip():\n",
    "            raise ValueError(\"Empty or unreadable PDF.\")\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading PDF: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db3ea43b-512f-4247-ad8e-6708abd3e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Resume\n",
    "def clean_resume(text):\n",
    "    text = re.sub(r'\\W+', ' ', text)  \n",
    "    doc = nlp(text.lower())           \n",
    "    clean_text = ' '.join([token.lemma_ for token in doc if token.text not in nlp.Defaults.stop_words])\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b98c35-5d5a-454f-856b-9b4f55a0afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get BERT Embeddings (Batch Processing)\n",
    "def get_bert_embedding(texts):\n",
    "    inputs = tokenizer(texts, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6965d48b-39ce-4a96-8c8c-764fc0ddc3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank Resumes using multiple models\n",
    "def rank_resumes(job_desc_embedding, resume_embeddings, tfidf_matrix, tfidf_vectorizer, job_desc_text):\n",
    "    similarity_scores = cosine_similarity(job_desc_embedding, resume_embeddings).flatten()\n",
    "    tfidf_scores = tfidf_matrix @ tfidf_vectorizer.transform([job_desc_text]).T\n",
    "    tfidf_scores = tfidf_scores.toarray().flatten()\n",
    "    final_scores = (0.7 * similarity_scores) + (0.3 * tfidf_scores / tfidf_scores.max()) \n",
    "    \n",
    "    # Prepare training data\n",
    "    X = final_scores.reshape(-1, 1)\n",
    "    y = [1 if score >= 0.5 else 0 for score in final_scores]\n",
    "    if len(set(y)) > 1:  # Ensure we have both classes\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        models = {\n",
    "            \"Logistic Regression\": LogisticRegression(),\n",
    "            \"SVM\": SVC(probability=True),\n",
    "            \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "            \"Neural Network\": MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500)\n",
    "        }\n",
    "        \n",
    "        best_model = None\n",
    "        best_accuracy = 0\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            acc = accuracy_score(y_test, model.predict(X_test))\n",
    "            print(f\"{name} Accuracy: {acc:.2f}\")\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_model = model\n",
    "    \n",
    "    ranked_indices = np.argsort(final_scores)[::-1]\n",
    "    return ranked_indices, final_scores[ranked_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ef1cc5f-90a3-4116-97eb-570117666fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "def save_results_to_csv(ranked_results):\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:\n",
    "        ranked_results.to_csv(tmp_file.name, index=False)\n",
    "        return tmp_file.name# Save results to CSV\n",
    "def save_results_to_csv(ranked_results):\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:\n",
    "        ranked_results.to_csv(tmp_file.name, index=False)\n",
    "        return tmp_file.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45479e71-7718-4583-bafb-c9a636e65483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Resumes\n",
    "def process_resumes(resume_files, job_desc_text):\n",
    "    resume_embeddings = []\n",
    "    cleaned_resumes = []\n",
    "    resume_names = []\n",
    "    \n",
    "    for resume_file in resume_files:\n",
    "        try:\n",
    "            pdf_text = extract_text_from_pdf(resume_file.name)\n",
    "            clean_text = clean_resume(pdf_text)\n",
    "            cleaned_resumes.append(clean_text)\n",
    "            resume_names.append(resume_file.name)\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Error processing {resume_file.name}: {str(e)}\"}\n",
    "    \n",
    "    if not cleaned_resumes:\n",
    "        return {\"error\": \"No valid resumes found.\"}\n",
    "    \n",
    "    resume_embeddings = get_bert_embedding(cleaned_resumes)\n",
    "    job_desc_embedding = get_bert_embedding([job_desc_text])\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(cleaned_resumes)\n",
    "    \n",
    "    ranked_indices, scores = rank_resumes(job_desc_embedding, resume_embeddings, tfidf_matrix, tfidf_vectorizer, job_desc_text)\n",
    "    \n",
    "    ranked_results = pd.DataFrame({\n",
    "        \"Rank\": range(1, len(ranked_indices) + 1),\n",
    "        \"Resume\": [resume_names[i].split('/')[-1] for i in ranked_indices],\n",
    "        \"Score\": [f\"{scores[i]:.4f}\" for i in ranked_indices]\n",
    "    })\n",
    "    \n",
    "    csv_file_path = save_results_to_csv(ranked_results)\n",
    "    return ranked_results.to_string(index=False), csv_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da94b2d7-e09d-4f47-bf64-d59a0ea02d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/.local/lib/python3.10/site-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.00\n",
      "SVM Accuracy: 1.00\n",
      "Random Forest Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 1.00\n",
      "Logistic Regression Accuracy: 0.80\n",
      "SVM Accuracy: 0.80\n",
      "Random Forest Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhishek/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Interface for Gradio\n",
    "def interface(job_desc_text, resume_files):\n",
    "    return process_resumes(resume_files, job_desc_text)\n",
    "\n",
    "# Gradio UI\n",
    "gr.Interface(\n",
    "    fn=interface,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Job Description\", placeholder=\"Enter the job description...\"),\n",
    "        gr.File(label=\"Upload Resumes\", file_count=\"multiple\")\n",
    "    ],\n",
    "    outputs=[\"text\", \"file\"],\n",
    "    title=\"AI-Powered Resume Ranking with ML Models\",\n",
    "    description=\"Upload resumes and enter a job description to rank the resumes based on relevance using ML models.\",\n",
    "    allow_flagging=\"never\"\n",
    ").launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446290f-a223-4ecd-83f9-788bead59fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27c85e-7747-43f6-aea5-2438d50dee12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
